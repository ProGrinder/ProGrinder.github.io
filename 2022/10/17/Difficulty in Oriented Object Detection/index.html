<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="&#34;auto&#34;"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="/img/default/greycat.ico"><link rel="icon" type="image/png" href="/img/default/greycat.ico"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="description" content=""><meta name="author" content="Grinder"><meta name="keywords" content=""><title>Difficulty in Oriented Object Detection - Be Grinder,for Better</title><link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="/lib/hint/hint.min.css"><link rel="stylesheet" href="https://cdn.staticfile.org/prism/1.21.0/themes/prism-coy.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1746382_qrhzb41budd.css"><link rel="stylesheet" href="/css/Normalize.css"><link rel="stylesheet" href="/css/GrinderStyle.css"><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script><meta name="generator" content="Hexo 5.2.0"></head><body><header style="height:72vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/">&nbsp;<strong>Grinder's Space</strong>&nbsp;</a> <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item"><a class="nav-link" href="/links/"><i class="iconfont icon-link-fill"></i> 友链</a></li><li class="nav-item" id="search-btn"><a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" href="javascript:">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div class="banner intro-2" id="background" parallax="true" style="background:url(/img/default/None.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.07)"><div class="container page-header text-center fade-in-up"><span class="h2" id="subtitle"></span><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-10-17 17:00" pubdate>2022年10月17日 下午</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i> 1.1k 字 </span><span class="post-meta mr-2"><i class="iconfont icon-clock-fill"></i> 23 分钟 </span><span id="busuanzi_container_page_pv" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"></span> 次</span></div></div></div></div></div></header><main><div class="container-fluid"><div class="row"><div class="d-none d-lg-block col-lg-2"></div><div class="col-lg-8 nopadding-md"><div class="container nopadding-md" id="board-ctn"><div class="py-5" id="board"><article class="post-content mx-auto" id="post"><h1 style="display:none">Difficulty in Oriented Object Detection</h1><div class="markdown-body" id="post-body"><h1 id="difficulty-in-oriented-object-detection"><a class="markdownIt-Anchor" href="#difficulty-in-oriented-object-detection"></a> Difficulty in Oriented Object Detection</h1><p>先把类分好，再做一个摘要的诵读。</p><p>需要维护的地方:</p><p>EndNote</p><p>ipad PDF</p><p>文件夹</p><h2 id="oriented-object-detection"><a class="markdownIt-Anchor" href="#oriented-object-detection"></a> Oriented Object Detection</h2><h3 id="one-stage"><a class="markdownIt-Anchor" href="#one-stage"></a> One Stage</h3><h4 id="anchor-based"><a class="markdownIt-Anchor" href="#anchor-based"></a> anchor-based</h4><h4 id="anchor-free"><a class="markdownIt-Anchor" href="#anchor-free"></a> anchor-free</h4><p>Axis Learning<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="Axis Learning for Orientated Objects Detection in Aerial Images[x]
">[5]</span></a></sup></p><p>ACE<sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote"><span class="hint--top hint--rounded" aria-label="ACE: Anchor-Free Corner Evolution for Real-Time Arbitrarily-Oriented Object Detection[x]
">[9]</span></a></sup></p><p>P-RSDet<sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><span class="hint--top hint--rounded" aria-label="Arbitrary-Oriented Object Detection in Remote Sensing Images Based on Polar Coordinates[x]
">[10]</span></a></sup></p><h3 id="two-stage"><a class="markdownIt-Anchor" href="#two-stage"></a> Two Stage</h3><h4 id="anchor-based-2"><a class="markdownIt-Anchor" href="#anchor-based-2"></a> anchor-based</h4><p>FR-O(DOTA)<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="DOTA: A Large-Scale Dataset for Object Detection in Aerial Images[x]
">[1]</span></a></sup></p><p>RoI Transformer<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span class="hint--top hint--rounded" aria-label="Learning RoI Transformer for Oriented Object Detection in Aerial Images[√]
">[7]</span></a></sup></p><p>text detection</p><p>R2CNN<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="R2^22CNN: Rotational Region CNN for Orientation Robust Scene Text Detection[x]
">[3]</span></a></sup></p><p>RRPN<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="Arbitrary-Oriented Scene Text Detection via Rotation Proposals[√]
">[4]</span></a></sup> =&gt; The implement of skew IoU computation</p><h3 id="else"><a class="markdownIt-Anchor" href="#else"></a> Else</h3><h4 id="loss"><a class="markdownIt-Anchor" href="#loss"></a> Loss</h4><p>适用于哪一类的cls reg one stage two stage</p><p>PIoU Loss<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="PIoU Loss: Towards Accurate Oriented Object Detection in Complex Environments[x]
">[2]</span></a></sup></p><p>ProbIoU<sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><span class="hint--top hint--rounded" aria-label="Gaussian Bounding Boxes and Probabilistic Intersection-over-Union for Object Detection[x]
">[8]</span></a></sup></p><h4 id="trick"><a class="markdownIt-Anchor" href="#trick"></a> Trick</h4><h2 id="difficulty-and-solution"><a class="markdownIt-Anchor" href="#difficulty-and-solution"></a> Difficulty and Solution</h2><h3 id="public-issues"><a class="markdownIt-Anchor" href="#public-issues"></a> Public Issues</h3><ol><li><p>航空图像的尺寸太大，使得常规目标检测网络显存爆炸；</p><blockquote><p>对密集小目标，通常的做法都是对原始的高分辨率图像进行裁剪分块再进行检测，但是这种方法效率很低，而且裁剪的图像块中的前景目标占比率可能很低</p></blockquote></li><li><p>目标尺寸小，在整幅图像中占的像素少，使得与周围背景很难分开；</p></li><li><p>目标分布稀疏且不均匀，使得检测效率低下；</p></li><li><p>密集目标存在遮挡或拥堵的情况，使得检测困难；</p></li><li><p>图像幅面宽，视场大，目标类型丰富，使得背景复杂，尺度变化大；</p></li><li><p>数据集中类别不均衡，如行人、车辆等目标类居多，而三轮车等目标类稀少，容易出现长尾效应；</p></li><li><p>卫星遥感图像是从空中俯拍的，因此角度不固定，方向多变，使得检测难度大。</p></li></ol><h3 id="specific-issues"><a class="markdownIt-Anchor" href="#specific-issues"></a> Specific Issues</h3><ol><li>角度的距离损失对<strong>高纵横比的物体</strong>不敏感<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="PIoU Loss: Towards Accurate Oriented Object Detection in Complex Environments[x]
">[2]</span></a></sup></li></ol><blockquote><ul><li>PIOU采用逐像素形式定义Loss损失<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="PIoU Loss: Towards Accurate Oriented Object Detection in Complex Environments[x]
">[2]</span></a></sup></li><li>ProbIoU提出一种比HBB和OBB更加能够贴合目标轮廓的表示形式，高斯边界框<sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><span class="hint--top hint--rounded" aria-label="Gaussian Bounding Boxes and Probabilistic Intersection-over-Union for Object Detection[x]
">[8]</span></a></sup></li></ul></blockquote><ol start="2"><li>基于Anchor-based的方法，如果采用<strong>rotated anchor</strong>先验，需要相当多的anchor，计算会非常耗时</li></ol><blockquote><ul><li>基于<strong>anchor-free</strong><ul><li>Axis Learning提出anchor-free的方法，通过预测物体的轴(头部尾部两点)来检测物体<sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="Axis Learning for Orientated Objects Detection in Aerial Images[x]
">[5]</span></a></sup></li><li>ACE 将轴对齐的边界框演化为定向四边形<sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote"><span class="hint--top hint--rounded" aria-label="ACE: Anchor-Free Corner Evolution for Real-Time Arbitrarily-Oriented Object Detection[x]
">[9]</span></a></sup></li><li>P-RSDet引入极坐标建模，回归一个极半径和两个极角<sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><span class="hint--top hint--rounded" aria-label="Arbitrary-Oriented Object Detection in Remote Sensing Images Based on Polar Coordinates[x]
">[10]</span></a></sup></li></ul></li><li>采用<strong>horizonal anchor</strong>先验<ul><li>RoI Transformer将RPN输出的水平锚框通过RoILearnerHRoI转换为旋转锚框RRoI<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="Towards Multi-class Object Detection in Unconstrained Remote Sensing Imagery[x]
">[6]</span></a></sup></li></ul></li></ul></blockquote><ol start="3"><li>角度参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">{\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord"><span class="mord mathdefault" style="margin-right:.02778em">θ</span></span></span></span></span>)的<strong>周期性</strong>带来的<strong>损失的不连续性</strong>和<strong>回归的不一致性</strong></li></ol><blockquote><ul><li>SCRDet提出了IoU-smooth L1 Loss<sup id="fnref:11" class="footnote-ref"><a href="#fn:11" rel="footnote"><span class="hint--top hint--rounded" aria-label="SCRDet: Towards More Robust Detection for Small, Cluttered and Rotated Objects[x]
">[11]</span></a></sup></li></ul></blockquote><p>ICN 单纯的迁移 =&gt; (2017ECCV)ICNet for Real-Time Semantic Segmentation on High-Resolution Imagest图像级联网络<sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="Towards Multi-class Object Detection in Unconstrained Remote Sensing Imagery[x]
">[6]</span></a></sup></p><h2 id="dota-doai"><a class="markdownIt-Anchor" href="#dota-doai"></a> DOTA-DOAI</h2><h3 id="dota10-task1"><a class="markdownIt-Anchor" href="#dota10-task1"></a> DOTA1.0 (Task1)</h3><p>recommend to read in DOTA1.0</p><style>table{font-size:13px}table th:first-of-type{font-size:15px;width:15%}table th:nth-of-type(2){font-size:15px;width:15%}table th:nth-of-type(3){font-size:15px;width:15%}table th:nth-of-type(4){font-size:15px;width:15%}table th:nth-of-type(5){font-size:15px;width:15%}table th:nth-of-type(6){font-size:15px;width:25%}</style><table><thead><tr><th style="text-align:center">Model</th><th style="text-align:center">Backbone</th><th style="text-align:center">mAP</th><th style="text-align:center">Paper Link</th><th style="text-align:center">Code Link</th><th style="text-align:center">Remark</th></tr></thead><tbody><tr><td style="text-align:center">FR-O (DOTA)</td><td style="text-align:center">ResNet101</td><td style="text-align:center">52.93</td><td style="text-align:center"><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2018/html/Xia_DOTA_A_Large-Scale_CVPR_2018_paper.html">CVPR2018</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/jessemelpolio/Faster_RCNN_for_DOTA">MXNet</a></td><td style="text-align:center">DOTA dataset, baseline</td></tr><tr><td style="text-align:center">PIoU Loss</td><td style="text-align:center">DLA34</td><td style="text-align:center">60.5</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2007.09584">ECCV2020</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/clobotics/piou">PyTorch</a></td><td style="text-align:center">IoU loss</td></tr><tr><td style="text-align:center">R2CNN</td><td style="text-align:center">ResNet101</td><td style="text-align:center">60.67</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.09579">arXiv:1706.09579</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/DetectionTeamUCAS/R2CNN_Faster-RCNN_Tensorflow">TF</a></td><td style="text-align:center">scene text, multi-task, different pooled sizes, baseline</td></tr><tr><td style="text-align:center">RRPN</td><td style="text-align:center">ResNet101</td><td style="text-align:center">61.01</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8323240">TMM</a> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.01086.pdf">arXiv:1703.01086</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/DetectionTeamUCAS/RRPN_Faster-RCNN_Tensorflow">TF</a></td><td style="text-align:center">scene text, rotation proposals, baseline</td></tr><tr><td style="text-align:center">Axis Learning</td><td style="text-align:center">ResNet101</td><td style="text-align:center">65.98</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://www.mdpi.com/2072-4292/12/6/908">Remote Sensing</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/RSIA-LIESMARS-WHU/AxisLearning">Pytorch</a></td><td style="text-align:center">axis, anchor free</td></tr><tr><td style="text-align:center">ICN</td><td style="text-align:center">ResNet101</td><td style="text-align:center">68.16</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-030-20893-6_10">ACCV2018</a></td><td style="text-align:center">-</td><td style="text-align:center">image cascade, multi-scale</td></tr><tr><td style="text-align:center">RoI Transformer</td><td style="text-align:center">ResNet101</td><td style="text-align:center">69.56</td><td style="text-align:center"><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Ding_Learning_RoI_Transformer_for_Oriented_Object_Detection_in_Aerial_Images_CVPR_2019_paper.pdf">CVPR2019</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/dingjiansw101/RoITransformer_DOTA">MXNet</a>, <a target="_blank" rel="noopener" href="https://github.com/dingjiansw101/AerialDetection">PyTorch</a>, <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmrotate">MMRotate</a></td><td style="text-align:center">roi transformer</td></tr><tr><td style="text-align:center">ProbIoU</td><td style="text-align:center">ResNet50</td><td style="text-align:center">70.04</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2106.06072">arXiv:2106.06072</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/ProbIOU">TF</a></td><td style="text-align:center">gaussian bounding boxes, hellinger distance</td></tr><tr><td style="text-align:center">ACE</td><td style="text-align:center">DLA34</td><td style="text-align:center">71.7</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9761381">TIP</a></td><td style="text-align:center">-</td><td style="text-align:center">corner point</td></tr><tr><td style="text-align:center">P-RSDet</td><td style="text-align:center">ResNet101</td><td style="text-align:center">72.30</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9272784/">Access</a></td><td style="text-align:center">-</td><td style="text-align:center">anchor free, polar coordinates</td></tr><tr><td style="text-align:center">SCRDet</td><td style="text-align:center">ResNet101</td><td style="text-align:center">72.61</td><td style="text-align:center"><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_SCRDet_Towards_More_Robust_Detection_for_Small_Cluttered_and_Rotated_ICCV_2019_paper.pdf">ICCV2019</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/SJTU-Thinklab-Det/R3Det_Tensorflow">RetinaNet-based</a>, <a target="_blank" rel="noopener" href="https://github.com/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation">R3Det-based</a></td><td style="text-align:center">attention, angular boundary problem</td></tr><tr><td style="text-align:center">O2-DNet</td><td style="text-align:center">Hourglass104</td><td style="text-align:center">72.8</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S0924271620302690">ISPRS</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1912.10694">arXiv:1912.10694</a></td><td style="text-align:center">-</td><td style="text-align:center">centernet, anchor free</td></tr><tr><td style="text-align:center">DRN</td><td style="text-align:center">Hourglass104</td><td style="text-align:center">73.23</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.09973">CVPR2020</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/Anymake/DRN_CVPR2020">code</a></td><td style="text-align:center">centernet, feature selection module, dynamic refinement head, new dataset (SKU110K-R)</td></tr><tr><td style="text-align:center">CFC-NET</td><td style="text-align:center">ResNet101</td><td style="text-align:center">73.50</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9488629">TGRS</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/ming71/CFC-Net">PyTorch</a></td><td style="text-align:center">critical feature, label assign, refine</td></tr><tr><td style="text-align:center">R3Det</td><td style="text-align:center">ResNet101</td><td style="text-align:center">73.79</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.05612">AAAI2021</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/yangxue0827/RotationDetection">TF</a>, <a target="_blank" rel="noopener" href="https://github.com/SJTU-Thinklab-Det/r3det-on-mmdetection">r3det-on-mmdetection</a>, <a target="_blank" rel="noopener" href="https://github.com/SJTU-Thinklab-Det/r3det-pytorch">r3det-pytorch</a>, <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmrotate">MMRotate</a></td><td style="text-align:center">refined single stage, feature alignment</td></tr><tr><td style="text-align:center">Gliding Vertex</td><td style="text-align:center">ResNet101</td><td style="text-align:center">75.02</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9001201">TPAMI</a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.09358">arXiv:1911.09358</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/MingtaoFu/gliding_vertex">PyTorch</a>, <a target="_blank" rel="noopener" href="https://github.com/open-mmlab/mmrotate">MMRotate</a></td><td style="text-align:center">quadrilateral bbox</td></tr><tr><td style="text-align:center">LO-Det</td><td style="text-align:center">Darknet53</td><td style="text-align:center">75.24</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9390310">TGRS</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2209.07709">arXiv:2209.07709</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/Shank2358/LO-Det">PyTorch</a></td><td style="text-align:center">lightweight</td></tr><tr><td style="text-align:center">EFN</td><td style="text-align:center">U-Net</td><td style="text-align:center">75.27</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://search.proquest.com/docview/2442440949?pq-origsite=gscholar&amp;fromopenview=true">Preprints</a></td><td style="text-align:center">-</td><td style="text-align:center">Field-based</td></tr><tr><td style="text-align:center">SAR</td><td style="text-align:center">ResNet152</td><td style="text-align:center">75.26</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9256343">Access</a></td><td style="text-align:center">-</td><td style="text-align:center">boundary problem</td></tr><tr><td style="text-align:center">TricubeNet</td><td style="text-align:center">Hourglass104</td><td style="text-align:center">75.26</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.11435">WACV2022</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/qjadud1994/TricubeNet">code</a></td><td style="text-align:center">2D tricube kernel</td></tr><tr><td style="text-align:center">Mask OBB</td><td style="text-align:center">ResNeXt101</td><td style="text-align:center">75.33</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://www.mdpi.com/2072-4292/11/24/2930/htm">Remote Sensing</a></td><td style="text-align:center">-</td><td style="text-align:center">attention, multi-task</td></tr><tr><td style="text-align:center">BBAVectors</td><td style="text-align:center">ResNet101</td><td style="text-align:center">75.36</td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2008.07043">WACV2021</a></td><td style="text-align:center"><a target="_blank" rel="noopener" href="https://github.com/yijingru/BBAVectors-Oriented-Object-Detection">PyTorch</a></td><td style="text-align:center">keypoint based</td></tr></tbody></table><p>remain 45</p><h2 id="reference"><a class="markdownIt-Anchor" href="#reference"></a> Reference</h2><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2018/html/Xia_DOTA_A_Large-Scale_CVPR_2018_paper.html">DOTA: A Large-Scale Dataset for Object Detection in Aerial Images</a>[x] <a href="#fnref:1" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2007.09584.pdf">PIoU Loss: Towards Accurate Oriented Object Detection in Complex Environments</a>[x] <a href="#fnref:2" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://arxiv.org/ftp/arxiv/papers/1706/1706.09579.pdf">R<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8141079999999999em;vertical-align:0"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>CNN: Rotational Region CNN for Orientation Robust Scene Text Detection</a>[x] <a href="#fnref:3" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.01086.pdf">Arbitrary-Oriented Scene Text Detection via Rotation Proposals</a>[√] <a href="#fnref:4" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span><a href="(https://www.mdpi.com/2072-4292/12/6/908)">Axis Learning for Orientated Objects Detection in Aerial Images</a>[x] <a href="#fnref:5" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:6" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-030-20893-6_10">Towards Multi-class Object Detection in Unconstrained Remote Sensing Imagery</a>[x] <a href="#fnref:6" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:7" class="footnote-text"><span><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Ding_Learning_RoI_Transformer_for_Oriented_Object_Detection_in_Aerial_Images_CVPR_2019_paper.pdf">Learning RoI Transformer for Oriented Object Detection in Aerial Images</a>[√] <a href="#fnref:7" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:8" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2106.06072.pdf">Gaussian Bounding Boxes and Probabilistic Intersection-over-Union for Object Detection</a>[x] <a href="#fnref:8" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:9" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9761381">ACE: Anchor-Free Corner Evolution for Real-Time Arbitrarily-Oriented Object Detection</a>[x] <a href="#fnref:9" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:10" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9272784/">Arbitrary-Oriented Object Detection in Remote Sensing Images Based on Polar Coordinates</a>[x] <a href="#fnref:10" rev="footnote" class="footnote-backref">↩</a></span></span></li><li><span id="fn:11" class="footnote-text"><span><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_SCRDet_Towards_More_Robust_Detection_for_Small_Cluttered_and_Rotated_ICCV_2019_paper.pdf">SCRDet: Towards More Robust Detection for Small, Cluttered and Rotated Objects</a>[x] <a href="#fnref:11" rev="footnote" class="footnote-backref">↩</a></span></span></li></ol></div></section></div><hr><div><div class="post-metas mb-3"><div class="post-meta mr-3"><i class="iconfont icon-category"></i> <a class="hover-with-bg" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a class="hover-with-bg" href="/tags/%E6%97%8B%E8%BD%AC%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">旋转目标检测</a> <a class="hover-with-bg" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></div></div><p class="note note-warning">本博客所有文章均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-NC-SA 4.0 协议</a> ，禁止商用，转载请注明出处！</p><div class="post-prevnext row"><article class="post-prev col-6"><a href="/2022/10/24/AI-Learning/20221024-Focal%20and%20Global%20Dlistillation/"><i class="iconfont icon-arrowleft"></i> <span class="hidden-mobile">Focal and Global Distillation</span> <span class="visible-mobile">上一篇</span></a></article><article class="post-next col-6"><a href="/2022/10/10/AI-Learning/20221011-Localization%20Distillation/"><span class="hidden-mobile">Localization Distillation</span> <span class="visible-mobile">下一篇</span> <i class="iconfont icon-arrowright"></i></a></article></div></div><article class="comments" id="comments"><div id="vcomments"></div><script type="text/javascript">function loadValine(){addScript("https://cdn.staticfile.org/valine/1.4.14/Valine.min.js",(function(){new Valine({el:"#vcomments",app_id:"zFsXUmmjrQgI8Mwc4q1hoeFX-gzGzoHsz",app_key:"lhfQutIrdSGngahzOrpkaKBU",placeholder:"说点什么吧！~(支持Markdown语法)",path:window.location.pathname,avatar:"retro",meta:["nick","mail","link"],pageSize:"10",lang:"zh-CN",highlight:!0,recordIP:!1,serverURLs:""})}))}waitElementVisible("vcomments",loadValine)</script><noscript>Please enable JavaScript to view the <a target="_blank" href="https://valine.js.org" rel="nofollow noopener noopener">comments powered by Valine.</a></noscript></article></article></div></div></div><div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div id="tocbot"></div></div></div></div></div></main><a id="scroll-top-button" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div><div id="aplayer"></div><script defer src="https://cdn.staticfile.org/aplayer/1.10.1/APlayer.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/aplayer/1.10.1/APlayer.min.css"><script type="text/javascript">var oldLoadAp=window.onload;window.onload=function(){oldLoadAp&&oldLoadAp(),new APlayer({container:document.getElementById("aplayer"),fixed:!0,autoplay:!1,loop:"all",order:"list",theme:"#b7daff",preload:"auto",lrcType:3,audio:[{name:"Reforget",artist:"Lauv",url:"/songs/Reforget.wav",cover:"/img/songs/Cover_Reforget.jpg",lrc:"/songs/lrc/Reforget.lrc"},{name:"Saint",artist:"Travis Scott & Quavo",url:"/songs/Saint.wav",cover:"/img/songs/Cover_Saint.jpg",lrc:"/songs/lrc/Saint.lrc"},{name:"Antisocial",artist:"Travis Scott & Ed Sheeran",url:"/songs/Antisocial.wav",cover:"/img/songs/Cover_Antisocial.jpg",lrc:"/songs/lrc/Antisocial.lrc"},{name:"Champion",artist:"Travis Scott & Nav",url:"/songs/Champion.wav",cover:"/img/songs/Cover_Champion.jpg",lrc:"/songs/lrc/Champion.lrc"},{name:"Smile",artist:"The Weekend & Juice WRLD",url:"/songs/Smile.wav",cover:"/img/songs/Cover_Smile.jpg",lrc:"/songs/lrc/Smile.lrc"},{name:"Starboy",artist:"The Weekend",url:"/songs/Starboy.wav",cover:"/img/songs/Cover_Starboy.jpg",lrc:"/songs/lrc/Starboy.lrc"},{name:"Sidewalks",artist:"The Weekend",url:"/songs/Sidewalks.wav",cover:"/img/songs/Cover_Sidewalks.jpg",lrc:"/songs/lrc/Sidewalks.lrc"},{name:"Reminder",artist:"The Weekend",url:"/songs/Reminder.wav",cover:"/img/songs/Cover_Reminder.jpg",lrc:"/songs/lrc/Reminder.lrc"},{name:"Die For You",artist:"The Weekend",url:"/songs/Die For You.wav",cover:"/img/songs/Cover_Die For You.jpg",lrc:"/songs/lrc/Die For You.lrc"},{name:"Pray For Me",artist:"The Weekend & Kendrick Lamar",url:"/songs/Pray For Me.wav",cover:"/img/songs/Cover_Pray For Me.jpg",lrc:"/songs/lrc/Pray For Me.lrc"}]})}</script><footer class="mt-5"><div class="text-center py-3"><div><br>Powered by: <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> Theme: <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="busuanzi_container_site_pv" style="display:none">总访问量 <span id="busuanzi_value_site_pv"></span> 次 </span><span id="busuanzi_container_site_uv" style="display:none">总访客数 <span id="busuanzi_value_site_uv"></span> 人</span></div></div></footer><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js"></script><script src="/js/debouncer.js"></script><script src="/js/main.js"></script><script src="/js/lazyload.js"></script><script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js"></script><script src="/js/clipboard-use.js"></script><script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js"></script><script>$(document).ready((function(){var t=$("#board-ctn").offset().top;tocbot.init({tocSelector:"#tocbot",contentSelector:"#post-body",headingSelector:"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:0,scrollSmooth:!0,headingsOffset:-t}),$(".toc-list-item").length>0&&$("#toc").css("visibility","visible")}))</script><script src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js"></script><script>var typed=new Typed("#subtitle",{strings:["  ","Difficulty in Oriented Object Detection&nbsp;"],cursorChar:"_",typeSpeed:72,loop:!1});typed.stop(),$(document).ready((function(){$(".typed-cursor").addClass("h2"),typed.start()}))</script><script src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js"></script><script>anchors.options={placement:"right",visible:"hover"};var el="h1,h2,h3,h4,h5,h6".split(","),res=[];for(item of el)res.push(".markdown-body > "+item);anchors.add(res.join(", "))</script><script src="/js/local-search.js"></script><script>var path="/local-search.xml",inputArea=document.querySelector("#local-search-input");inputArea.onclick=function(){searchFunc(path,"local-search-input","local-search-result"),this.onclick=null}</script><script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"><script>$("#post img:not(.no-zoom img, img[no-zoom]), img[zoom]").each((function(){var t=document.createElement("a");$(t).attr("data-fancybox","images"),$(t).attr("href",$(this).attr("src")),$(this).wrap(t)}))</script><link rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.11.1/katex.min.css"><script defer>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?f9aad97d2fdeed725d5d52997eaebaa9";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></body></html>